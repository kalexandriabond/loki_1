{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "from operator import sub, add\n",
    "import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/coaxlab/Dropbox/loki_1/fmri_experiment/experimental_parameters'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_path = os.path.expanduser('~') #need this to get correct home dir. across operating systems\n",
    "\n",
    "\n",
    "exp_param_path = home_path + \"/Dropbox/loki_1/fmri_experiment/experimental_parameters/\"\n",
    "img_path = home_path + \"/Dropbox/loki_1/fmri_experiment/images/symm_greebles/\"\n",
    "\n",
    "    \n",
    "os.chdir(exp_param_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_families = 5\n",
    "n_trials = 600\n",
    "test_prop = .50\n",
    "n_test_repetitions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images(img_path=img_path, n_families=n_families, n_trials=n_trials):    \n",
    "    \n",
    "    family_indices = np.arange(0,n_families)\n",
    "    nominal_families = np.arange(1,n_families+1)\n",
    "\n",
    "    m_family_list = [glob.glob(img_path+'m'+str(family)+'~*v1.tif') for family in nominal_families] #chose view 1\n",
    "    f_family_list = [glob.glob(img_path+'f'+str(family)+'~*v1.tif') for family in nominal_families]\n",
    "    \n",
    "    \n",
    "    return m_family_list, f_family_list, family_indices, nominal_families\n",
    "\n",
    "\n",
    "\n",
    "def check_greeble_samples(m_family_list, f_family_list, family_indices, nominal_families): \n",
    "    #error checking\n",
    "    \n",
    "    m_family_sample_count = [len(m_family_list[family_idx]) for family_idx in family_indices] #n. samples are unequal across gender \n",
    "    f_family_sample_count = [len(f_family_list[family_idx]) for family_idx in family_indices] #so count them to figure out test set\n",
    "\n",
    "    n_greebles_per_family = np.unique(list(map(add, m_family_sample_count, f_family_sample_count)))\n",
    "    n_unique_greebles_per_family = len(n_greebles_per_family) == 1\n",
    "    \n",
    "    \n",
    "    n_families = len(m_family_list)\n",
    "    n_samples_per_family = n_trials // n_families #each family will be sampled n times \n",
    "    \n",
    "    n_families_equal = len(m_family_list) == len(f_family_list)\n",
    "    \n",
    "    \n",
    "    print('Number of families equal across sex: ', n_families_equal)\n",
    "    print('Number of families: ', n_families, 'Number of family repetitions: ', n_samples_per_family)\n",
    "    print('Number of greebles per family: ', n_greebles_per_family)\n",
    "    print('Equal number of greebles per family: ', n_unique_greebles_per_family)\n",
    "\n",
    "    return m_family_sample_count, f_family_sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_training_test_samples(m_family_sample_count, f_family_sample_count, test_prop=test_prop,\n",
    "                                n_test_repetitions=n_test_repetitions):\n",
    "    \n",
    "    n_test_per_m_fam = [int(test_prop * m_family_sample_count[family_idx]) for family_idx in family_indices] #n. samples are unequal across gender \n",
    "    n_test_per_f_fam = [int(test_prop * f_family_sample_count[family_idx]) for family_idx in family_indices] #so count them to figure out training set\n",
    "\n",
    "    n_training_per_m_fam = map(sub, m_family_sample_count, n_test_per_m_fam)\n",
    "    n_training_per_f_fam = map(sub, f_family_sample_count, n_test_per_f_fam)\n",
    "\n",
    "\n",
    "    n_test_greebles_per_fam = np.unique(map(add, n_test_per_m_fam, n_test_per_f_fam))\n",
    "    n_test_trials = n_test_greebles_per_fam * n_test_repetitions * n_families \n",
    "\n",
    "    training_greebles_m = [list(np.random.choice(m_family_list[family_idx], n_training_per_m_fam[family_idx], replace=False)) for family_idx in family_indices]\n",
    "    training_greebles_f = [list(np.random.choice(f_family_list[family_idx], n_training_per_f_fam[family_idx], replace=False)) for family_idx in family_indices]\n",
    "\n",
    "    summed_m_family_list = sum(m_family_list,[]) #summed for testing \n",
    "    summed_f_family_list = sum(f_family_list,[])\n",
    "\n",
    "    summed_training_greebles_m = sum(training_greebles_m,[])#summed for random sampling across families for each trial\n",
    "    summed_training_greebles_f = sum(training_greebles_f,[])\n",
    "    \n",
    "\n",
    "    test_greebles_m = list(np.setdiff1d(summed_m_family_list, summed_training_greebles_m))\n",
    "    test_greebles_f = list(np.setdiff1d(summed_f_family_list, summed_training_greebles_f))\n",
    "    test_greeble_vec = test_greebles_f + test_greebles_m\n",
    "    shuffle(test_greeble_vec) #shuffle so that m/f are randomly placed\n",
    "    \n",
    "    training_vec_choice_m = list(np.random.choice(summed_training_greebles_m, n_trials, replace=True)) \n",
    "    training_vec_choice_f = list(np.random.choice(summed_training_greebles_f, n_trials, replace=True)) \n",
    "    \n",
    "    \n",
    "    training_vec_choice = training_vec_choice_m + training_vec_choice_f\n",
    "    test_vec_choice = list(np.random.choice(test_greeble_vec, n_test_trials, replace=True)) #could instead preesent each one exactly twice. will need to ask.\n",
    "    \n",
    "    return(training_vec_choice, test_vec_choice, test_greeble_vec,\n",
    "training_vec_choice_m, training_vec_choice_f, summed_training_greebles_m, summed_training_greebles_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_training_test_samples(training_vec_choice, test_vec_choice):\n",
    "    \n",
    "    #double check that training and test samples do not overlap \n",
    "    train_test_overlap = bool(set(training_vec_choice) & set(test_vec_choice))\n",
    "    print('Training set does not overlap with the test set: ', (train_test_overlap == 0))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_images(training_vec_choice_f, training_vec_choice_m, test_greeble_vec, img_path=img_path):\n",
    "\n",
    "    #separate file from path \n",
    "    f_training_greebles_parsed = pd.DataFrame([training_vec_choice_f[trial].split(img_path)[1] for trial in range(len(training_vec_choice_f))])\n",
    "    m_training_greebles_parsed = pd.DataFrame([training_vec_choice_m[trial].split(img_path)[1] for trial in range(len(training_vec_choice_m))])\n",
    "    test_greebles_parsed = pd.DataFrame([test_greeble_vec[trial].split(img_path)[1] for trial in range(len(test_greeble_vec))])\n",
    "\n",
    "    return f_training_greebles_parsed, m_training_greebles_parsed, test_greebles_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_greeble_training_set(m_training_greebles_parsed, f_training_greebles_parsed, exp_param_path=exp_param_path): \n",
    "\n",
    "    training_images_df = pd.DataFrame(np.column_stack([m_training_greebles_parsed, f_training_greebles_parsed]),\n",
    "                               columns = ['m_image','f_image'])\n",
    "    training_images_df.to_csv(exp_param_path + 'training_greeble_images.csv', header=True, index_label=True, index=False)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_greeble_test_set(test_greebles_parsed, exp_param_path=exp_param_path):      \n",
    "    \n",
    "    test_images_df = pd.DataFrame(np.array(test_greebles_parsed), columns = ['image'])\n",
    "    test_images_df.to_csv(exp_param_path + 'test_greeble_images.csv', header=True, index_label=True, index=False)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of families equal across sex:  True\n",
      "Number of families:  5 Number of family repetitions:  120\n",
      "Number of greebles per family:  [16]\n",
      "Equal number of greebles per family:  True\n"
     ]
    }
   ],
   "source": [
    "m_family_list, f_family_list, family_indices, nominal_families = select_images()\n",
    "m_family_sample_count, f_family_sample_count = check_greeble_samples(m_family_list, f_family_list, family_indices, nominal_families)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_vec_choice, test_vec_choice, test_greeble_vec,\n",
    "training_vec_choice_m, training_vec_choice_f, summed_training_greebles_m, summed_training_greebles_f) = select_training_test_samples(m_family_sample_count, f_family_sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set does not overlap with the test set: ', True)\n"
     ]
    }
   ],
   "source": [
    "check_training_test_samples(training_vec_choice, test_vec_choice)\n",
    "f_training_greebles_parsed, m_training_greebles_parsed, test_greebles_parsed = parse_images(training_vec_choice_f, training_vec_choice_m, test_greeble_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_greeble_training_set(m_training_greebles_parsed, f_training_greebles_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_greeble_test_set(test_greebles_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_prob_vectors(n_trials = 800, n_targets = 2, hc_p=.65,\n",
    "                        mc_p=.75, lc_p=.85, print_pooled_c_prob=1):\n",
    "\n",
    "    lc_binary_t0, lc_binary_t1 = np.zeros((n_trials)), np.zeros((n_trials))\n",
    "    mc_binary_t0, mc_binary_t1 = np.zeros((n_trials)), np.zeros((n_trials))\n",
    "    hc_binary_t0, hc_binary_t1 = np.zeros((n_trials)), np.zeros((n_trials))\n",
    "\n",
    "    mc_binary_t1 = np.zeros((n_trials))\n",
    "    for t in np.arange(0,n_trials):\n",
    "        test_dist = np.random.uniform()\n",
    "        if test_dist < mc_p: \n",
    "            mc_binary_t1[t]=1\n",
    "        else: \n",
    "            mc_binary_t1[t]=0\n",
    "\n",
    "    mc_binary_t0[mc_binary_t1 == 0] = 1\n",
    "    mc_binary_t0 = mc_binary_t0 > 0 \n",
    "    mc_binary_t1 = mc_binary_t1 > 0 \n",
    "\n",
    "\n",
    "    lc_binary_t1 = np.zeros((n_trials))\n",
    "    for t in np.arange(0,n_trials):\n",
    "        test_dist = np.random.uniform(0, 1, 1)\n",
    "        if test_dist < lc_p: \n",
    "            lc_binary_t1[t]=1\n",
    "        else: \n",
    "            lc_binary_t1[t]=0\n",
    "\n",
    "    lc_binary_t0[lc_binary_t1 == 0] = 1\n",
    "    lc_binary_t0 = lc_binary_t0 > 0 \n",
    "    lc_binary_t1 = lc_binary_t1 > 0 \n",
    "\n",
    "    hc_binary_t1 = np.zeros((n_trials))\n",
    "    for t in np.arange(0,n_trials):\n",
    "        test_dist = np.random.uniform(0, 1, 1)\n",
    "        if test_dist < hc_p: \n",
    "            hc_binary_t1[t]=1\n",
    "        else: \n",
    "            hc_binary_t1[t]=0\n",
    "    hc_binary_t0[hc_binary_t1 == 0] = 1\n",
    "    hc_binary_t0 = hc_binary_t0 > 0 \n",
    "    hc_binary_t1 = hc_binary_t1 > 0 \n",
    "\n",
    "    print('lc_p(rewarding_target) :', np.sum(lc_binary_t1)/n_trials)\n",
    "    print('lc_p(unrewarding_target) :', np.sum(lc_binary_t0)/n_trials)\n",
    "\n",
    "    print('mc_p(rewarding_target) :', np.sum(mc_binary_t1)/n_trials)\n",
    "    print('hc_p(rewarding_target) :', np.sum(hc_binary_t1)/n_trials)\n",
    "    t_range = np.arange(1,n_trials+1)\n",
    "    hc_cumulative_p = np.cumsum(hc_binary_t1)/t_range\n",
    "    mc_cumulative_p = np.cumsum(mc_binary_t1)/t_range\n",
    "    lc_cumulative_p = np.cumsum(lc_binary_t1)/t_range\n",
    "    if print_pooled_c_prob == 1: \n",
    "        plt.rcParams['font.size'] = 18\n",
    "        plt.figure()\n",
    "        plt.plot(hc_cumulative_p, 'r.', label='high conflict')\n",
    "        plt.plot(mc_cumulative_p, 'b.', label='moderate conflict')\n",
    "        plt.plot(lc_cumulative_p, 'g.', label='low conflict')\n",
    "        plt.legend()\n",
    "        plt.ylabel('cumulative p(max_reward)')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylim([0.5,1.01])\n",
    "    \n",
    "    return(lc_binary_t0, lc_binary_t1, mc_binary_t0,mc_binary_t1, hc_binary_t0, hc_binary_t1, hc_cumulative_p,mc_cumulative_p,lc_cumulative_p,n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_reward_values(lc_binary_t0, lc_binary_t1, mc_binary_t0, mc_binary_t1, hc_binary_t0, hc_binary_t1,n_trials, r_mu=3, r_std=1, n_trials_expected = 600):\n",
    "\n",
    "    \n",
    "    #reward values \n",
    "    mu_rewards = np.repeat(r_mu, n_trials_expected)\n",
    "    std_rewards = np.repeat(r_std, n_trials_expected)\n",
    "\n",
    "    hc_rewards = np.random.normal(loc=r_mu, scale=r_std, size=n_trials)\n",
    "    mc_rewards = np.random.normal(loc=r_mu, scale=r_std, size=n_trials)\n",
    "    lc_rewards = np.random.normal(loc=r_mu, scale=r_std, size=n_trials)\n",
    "    \n",
    "\n",
    "    hc_rewards_t0 = np.zeros(hc_binary_t0.shape)\n",
    "    mc_rewards_t0 = np.zeros(mc_binary_t0.shape)\n",
    "    lc_rewards_t0 = np.zeros(lc_binary_t0.shape)\n",
    "\n",
    "    hc_rewards_t1 = np.zeros_like(hc_rewards_t0)\n",
    "    mc_rewards_t1 = np.zeros_like(mc_rewards_t0)\n",
    "    lc_rewards_t1 = np.zeros_like(lc_rewards_t0)\n",
    "\n",
    "    hc_rewards_t0[hc_binary_t0] = hc_rewards[hc_binary_t0]\n",
    "    hc_rewards_t1[~hc_binary_t0] = hc_rewards[~hc_binary_t0]\n",
    "\n",
    "    mc_rewards_t0[mc_binary_t0] = mc_rewards[mc_binary_t0]\n",
    "    mc_rewards_t1[~mc_binary_t0] = mc_rewards[~mc_binary_t0]\n",
    "\n",
    "    lc_rewards_t0[lc_binary_t0] = lc_rewards[lc_binary_t0]\n",
    "    lc_rewards_t1[~lc_binary_t0] = lc_rewards[~lc_binary_t0]\n",
    "    \n",
    "    return(hc_rewards, mc_rewards, lc_rewards, \n",
    "           hc_rewards_t0, hc_rewards_t1, mc_rewards_t0, mc_rewards_t1, \n",
    "           lc_rewards_t0, lc_rewards_t1,mu_rewards,std_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_changepoint_indices(n_trials, lv_lambda=35, mv_lambda=25, hv_lambda=15):\n",
    "    \n",
    "    #volatility \n",
    "    lv_size, mv_size, hv_size = int(n_trials/lv_lambda),int(n_trials/mv_lambda),  int(n_trials/hv_lambda)\n",
    "    #find change point indices and slice to fit n_trials \n",
    "    lv_lam = np.cumsum(np.random.poisson(lam=lv_lambda,size=lv_size))\n",
    "    mv_lam = np.cumsum(np.random.poisson(lam=mv_lambda,size=mv_size))\n",
    "    hv_lam = np.cumsum(np.random.poisson(lam=hv_lambda,size=hv_size))\n",
    "\n",
    "    hv_lam = hv_lam[hv_lam < n_trials]\n",
    "    mv_lam = mv_lam[mv_lam < n_trials]\n",
    "    lv_lam = lv_lam[lv_lam < n_trials]\n",
    "    \n",
    "    return(hv_lam, mv_lam, lv_lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_changepoints(lc_rewards_t0, mc_rewards_t0, hc_rewards_t0, \n",
    "                       lc_rewards_t1, mc_rewards_t1, hc_rewards_t1,\n",
    "                       hv_lam, mv_lam, lv_lam, n_trials,\n",
    "                       lv_lambda=30, mv_lambda=20, hv_lambda=10):\n",
    "\n",
    "    lc_reward_arr = np.transpose(np.array((lc_rewards_t0, lc_rewards_t1)))\n",
    "    mc_reward_arr = np.transpose(np.array((mc_rewards_t0, mc_rewards_t1)))\n",
    "    hc_reward_arr = np.transpose(np.array((hc_rewards_t0, hc_rewards_t1)))\n",
    "    \n",
    "    #also write generative ps \n",
    "    lc_rewards_flipped = np.array([lc_reward_arr[n,::-1] if np.sum(n>=mv_lam)%2 else lc_reward_arr[n,:] for n in range(len(lc_reward_arr))])\n",
    "    \n",
    "\n",
    "    mc_rewards_flipped = np.array([mc_reward_arr[n,::-1] if np.sum(n>=mv_lam)%2 else mc_reward_arr[n,:] for n in range(len(mc_reward_arr))])\n",
    "\n",
    "    mc_rewards_flipped_lv = np.array([mc_reward_arr[n,::-1] if np.sum(n>=lv_lam)%2 else mc_reward_arr[n,:] for n in range(len(mc_reward_arr))])\n",
    "\n",
    "    mc_rewards_flipped_hv = np.array([mc_reward_arr[n,::-1] if np.sum(n>=hv_lam)%2 else mc_reward_arr[n,:] for n in range(len(mc_reward_arr))])\n",
    "\n",
    "    hc_rewards_flipped = np.array([hc_reward_arr[n,::-1] if np.sum(n>=mv_lam)%2 else hc_reward_arr[n,:] for n in range(len(hc_reward_arr))])\n",
    "    \n",
    "    #mark trials with cp indicator\n",
    "    lv_cp_vec = np.zeros((n_trials), dtype=bool)\n",
    "    mv_cp_vec = np.zeros((n_trials), dtype=bool)\n",
    "    hv_cp_vec = np.zeros((n_trials), dtype=bool)\n",
    "\n",
    "    lv_cp_vec[lv_lam] = 1\n",
    "    mv_cp_vec[mv_lam] = 1\n",
    "    hv_cp_vec[hv_lam] = 1\n",
    "    \n",
    "    cp_lv_epoch_idx = list(np.where(lv_cp_vec == 1)[0])\n",
    "    cp_lv_epoch_idx.insert(0,0)\n",
    "    cp_lv_epoch_idx.append(n_trials)\n",
    "    cp_hv_epoch_idx = list(np.where(hv_cp_vec == 1)[0])\n",
    "    cp_hv_epoch_idx.insert(0,0)\n",
    "    cp_hv_epoch_idx.append(n_trials)\n",
    "    cp_mv_epoch_idx = list(np.where(mv_cp_vec == 1)[0])\n",
    "    cp_mv_epoch_idx.insert(0,0)\n",
    "    cp_mv_epoch_idx.append(n_trials)\n",
    "\n",
    "    cp_lv_epoch_len = np.diff(cp_lv_epoch_idx)\n",
    "    cp_mv_epoch_len = np.diff(cp_mv_epoch_idx)\n",
    "    cp_hv_epoch_len = np.diff(cp_hv_epoch_idx)\n",
    "    \n",
    "    return(lc_rewards_flipped, mc_rewards_flipped,mc_rewards_flipped_lv, mc_rewards_flipped_hv,hc_rewards_flipped, cp_lv_epoch_len, cp_mv_epoch_len, cp_hv_epoch_len, cp_lv_epoch_idx, cp_hv_epoch_idx,cp_mv_epoch_idx, lv_cp_vec, mv_cp_vec, hv_cp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_obs_changepoints(lc_rewards_flipped, mc_rewards_flipped,mc_rewards_flipped_lv, mc_rewards_flipped_hv,hc_rewards_flipped, n_trials): \n",
    "#observed reward-identity changes (not \"real\" changepoints)\n",
    "#conflict conditions\n",
    "    lc_obs_cp_vec = np.zeros((n_trials))\n",
    "    mc_obs_cp_vec = np.zeros((n_trials))\n",
    "    mc_obs_cp_vec_lv = np.zeros((n_trials))\n",
    "    mc_obs_cp_vec_hv = np.zeros((n_trials))\n",
    "    hc_obs_cp_vec = np.zeros((n_trials))\n",
    "\n",
    "    lc_rewards_flipped_vec = lc_rewards_flipped != 0 \n",
    "    mc_rewards_flipped_vec = mc_rewards_flipped != 0 \n",
    "    mc_rewards_flipped_vec_lv = mc_rewards_flipped_lv != 0 \n",
    "    mc_rewards_flipped_vec_hv = mc_rewards_flipped_hv != 0 \n",
    "    hc_rewards_flipped_vec = hc_rewards_flipped != 0 \n",
    "\n",
    "    lc_obs_cp_idx = np.where(lc_rewards_flipped_vec[:-1] != lc_rewards_flipped_vec[1:])[0]\n",
    "    mc_obs_cp_idx = np.where(mc_rewards_flipped_vec[:-1] != mc_rewards_flipped_vec[1:])[0]\n",
    "    mc_obs_cp_idx_lv = np.where(mc_rewards_flipped_vec_lv[:-1] != mc_rewards_flipped_vec_lv[1:])[0]\n",
    "    mc_obs_cp_idx_hv = np.where(mc_rewards_flipped_vec_hv[:-1] != mc_rewards_flipped_vec_hv[1:])[0]\n",
    "    hc_obs_cp_idx = np.where(hc_rewards_flipped_vec[:-1] != hc_rewards_flipped_vec[1:])[0]\n",
    "\n",
    "    lc_obs_cp_vec[lc_obs_cp_idx+1] = 1\n",
    "    mc_obs_cp_vec[mc_obs_cp_idx+1] = 1\n",
    "    mc_obs_cp_vec_lv[mc_obs_cp_idx_lv+1] = 1\n",
    "    mc_obs_cp_vec_hv[mc_obs_cp_idx_hv+1] = 1\n",
    "    hc_obs_cp_vec[hc_obs_cp_idx+1] = 1\n",
    "    \n",
    "    return(lc_obs_cp_vec,mc_obs_cp_vec,mc_obs_cp_vec_lv,\n",
    "           mc_obs_cp_vec_hv,hc_obs_cp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_empirical_cprob(cp_lv_epoch_len,cp_mv_epoch_len, cp_hv_epoch_len, cp_mv_epoch_idx, cp_lv_epoch_idx, cp_hv_epoch_idx,\n",
    "                        lc_rewards_flipped, mc_rewards_flipped_hv,mc_rewards_flipped_lv, hc_rewards_flipped, n_trials, print_epoch_cprob=1, hc_p=.65,\n",
    "                        mc_p=.75, lc_p=.85):\n",
    "\n",
    "    #calculate cumulative prob. for each epoch \n",
    "    #need to set reshape value to actual cps \n",
    "    hc_test = []\n",
    "    lc_test = []\n",
    "    hv_test = []\n",
    "    lv_test = []\n",
    "\n",
    "    for epoch in range(len(cp_mv_epoch_len)):\n",
    "        hc_test.append(np.cumsum((hc_rewards_flipped[cp_mv_epoch_idx[epoch]:\n",
    "    cp_mv_epoch_idx[epoch+1],0] > 0))\n",
    "                  /np.arange(1,cp_mv_epoch_len[epoch]+1))\n",
    "\n",
    "    for epoch in range(len(cp_mv_epoch_len)):\n",
    "        lc_test.append(np.cumsum((lc_rewards_flipped[cp_mv_epoch_idx[epoch]:\n",
    "    cp_mv_epoch_idx[epoch+1],0] > 0))\n",
    "                  /np.arange(1,cp_mv_epoch_len[epoch]+1))\n",
    "\n",
    "\n",
    "    for epoch in range(len(cp_lv_epoch_len)):\n",
    "        lv_test.append(np.cumsum((mc_rewards_flipped_lv[cp_lv_epoch_idx[epoch]:\n",
    "    cp_lv_epoch_idx[epoch+1],0] > 0))\n",
    "                  /np.arange(1,cp_lv_epoch_len[epoch]+1))\n",
    "\n",
    "    for epoch in range(len(cp_hv_epoch_len)):\n",
    "        hv_test.append(np.cumsum((mc_rewards_flipped_hv[cp_hv_epoch_idx[epoch]:\n",
    "    cp_hv_epoch_idx[epoch+1],0] > 0))\n",
    "                  /np.arange(1,cp_hv_epoch_len[epoch]+1))\n",
    "\n",
    "    peak_p_reward_hc = [epoch[-1] for epoch in hc_test]\n",
    "    peak_p_reward_lc = [epoch[-1] for epoch in lc_test]\n",
    "    peak_p_reward_hv = [epoch[-1] for epoch in hv_test]\n",
    "    peak_p_reward_lv = [epoch[-1] for epoch in lv_test]\n",
    "\n",
    "\n",
    "    print(np.mean(peak_p_reward_hc[::2]), np.mean(peak_p_reward_lc[::2]), \n",
    "    np.mean(peak_p_reward_lv[::2]), np.mean(peak_p_reward_hv[::2]))\n",
    "\n",
    "    lc_cprob_epoch = np.hstack(lc_test).flatten()\n",
    "    hc_cprob_epoch = np.hstack(hc_test).flatten()\n",
    "    hv_cprob_epoch = np.hstack(hv_test).flatten()\n",
    "    lv_cprob_epoch = np.hstack(lv_test).flatten()\n",
    "\n",
    " \n",
    "    if print_epoch_cprob == 1: \n",
    "        plt.rcParams['figure.figsize'] = (10,10)\n",
    "        plt.rcParams['font.size'] = 18\n",
    "        plt.figure()\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(lc_cprob_epoch, 'b.-')\n",
    "        plt.axhline(lc_p, alpha = 0.5, color='k')\n",
    "        plt.axhline(1-lc_p, alpha = 0.5, color='k')\n",
    "        plt.title('low conflict')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('cumulative p(r|correct) per epoch')\n",
    "        plt.show()\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.plot(hc_cprob_epoch, 'r.-')\n",
    "        plt.title('high conflict')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('cumulative p(r|correct) per epoch')\n",
    "        plt.axhline(hc_p, alpha = 0.5, color='k')\n",
    "        plt.axhline(1-hc_p, alpha = 0.5, color='k')\n",
    "        plt.show()\n",
    "        \n",
    "#     if animate_plot == 1: \n",
    "#         x = np.arange(0,n_trials)\n",
    "\n",
    "#         # target 0 and 1 p(r)\n",
    "#         t1t2_reward_fig = plt.figure(figsize=(20, 10))\n",
    "#         plt.plot()\n",
    "#         plt.xlim(0, n_trials)\n",
    "#         plt.ylim(-.05, 1.05)\n",
    "#         graph, = plt.plot([], [], 'k-')\n",
    "#         graph2, = plt.plot([], [], 'ro')\n",
    "\n",
    "#         plt.title(\"cumulative p(reward)\",fontsize = 40)\n",
    "#         plt.xlabel(\"trial\", fontsize = 30)\n",
    "#         plt.ylabel(\"cumulative p(reward|correct)\", fontsize = 30)\n",
    "#         plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "#         filename='hv'\n",
    "    \n",
    "\n",
    "#         def animate(i):\n",
    "# #             graph.set_data(x[:i+1], muRewardDelta_vec[:i+1])\n",
    "#             graph2.set_data(x[:i+1], hv_cprob_epoch[:i+1])\n",
    "#             return graph\n",
    "\n",
    "#         anim = FuncAnimation(t1t2_reward_fig, animate, frames=n_trials, interval=10)\n",
    "#     #     plt.show()\n",
    "#         HTML(anim.to_html5_video())\n",
    "\n",
    "#         anim.save('sample_tc_' + filename +'.mp4',extra_args=['-vcodec', 'libx264'])\n",
    "        \n",
    "        return(lc_cprob_epoch, hc_cprob_epoch,hv_cprob_epoch,lv_cprob_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_expected_val(n_trials):\n",
    "    #performance criterion for 80/20 p. in frank's task is .65 choosing high val., .5 for 60/40 \n",
    "    #values from Frank, Worack, & Curran 2005 \n",
    "\n",
    "    frank_lc_crit_highVal = .65\n",
    "    frank_lc_crit_lowVal = 1 - frank_lc_crit_highVal\n",
    "    lc_p_highVal = .85 \n",
    "    lc_p_lowVal = 1-lc_p_highVal \n",
    "\n",
    "    frank_hc_crit_highVal = .5\n",
    "    frank_hc_crit_lowVal = 1 - frank_hc_crit_highVal\n",
    "    hc_p_highVal = .65\n",
    "    hc_p_lowVal = 1-hc_p_highVal \n",
    "\n",
    "    pts_per_trial = 3\n",
    "    total_cost = -1*n_trials \n",
    "\n",
    "\n",
    "    hv_target_pts_lc = frank_lc_crit_highVal*lc_p_highVal*(n_trials*pts_per_trial)\n",
    "    lv_target_pts_lc = frank_lc_crit_lowVal*lc_p_lowVal*(n_trials*pts_per_trial)\n",
    "\n",
    "    hv_target_pts_hc = frank_hc_crit_highVal*hc_p_highVal*(n_trials*pts_per_trial)\n",
    "    lv_target_pts_hc = frank_hc_crit_lowVal*hc_p_lowVal*(n_trials*pts_per_trial)\n",
    "\n",
    "    expected_val_lc = hv_target_pts_lc + lv_target_pts_lc + total_cost\n",
    "    expected_val_hc = hv_target_pts_hc + lv_target_pts_hc + total_cost\n",
    "\n",
    "    print('expected_val low conflict ', expected_val_lc,'\\nexpected_val high conflict ', expected_val_hc)\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slice_trials(hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p,lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards, n_input_trials=300): \n",
    "    \n",
    "    cp_list = [mv_cp_vec,lv_cp_vec,hv_cp_vec] \n",
    "    \n",
    "    next_cp = []\n",
    "    for l in cp_list: \n",
    "        #INDEX OF NEXT CP AFTER EXACTLY n/2 trials\n",
    "        next_cp_idx = np.asarray(np.argwhere(l))\n",
    "        next_cp.append(next_cp_idx[next_cp_idx > n_input_trials][0])  \n",
    "        \n",
    "        print(next_cp)\n",
    "    \n",
    "    mv_slice,lv_slice,hv_slice = next_cp\n",
    "           \n",
    "\n",
    "    hc_rewards_flipped = np.vstack((hc_rewards_flipped[:n_input_trials,:], hc_rewards_flipped[mv_slice:mv_slice+n_input_trials, :]))\n",
    "    hc_cumulative_p = np.hstack((hc_cumulative_p[:n_input_trials], hc_cumulative_p[mv_slice:mv_slice+n_input_trials]))\n",
    "    hc_cprob_epoch = np.hstack((hc_cprob_epoch[:n_input_trials], hc_cprob_epoch[mv_slice:mv_slice+n_input_trials]))\n",
    "    hc_obs_cp_vec = np.hstack((hc_obs_cp_vec[:n_input_trials], hc_obs_cp_vec[mv_slice:mv_slice+n_input_trials]))\n",
    "    \n",
    "    mv_cp_vec = np.hstack((mv_cp_vec[:n_input_trials], mv_cp_vec[mv_slice:mv_slice+n_input_trials]))\n",
    "    \n",
    "    lv_cp_vec = np.hstack((lv_cp_vec[:n_input_trials], lv_cp_vec[lv_slice:lv_slice+n_input_trials]))\n",
    "   \n",
    "    hv_cp_vec = np.hstack((hv_cp_vec[:n_input_trials], hv_cp_vec[hv_slice:hv_slice+n_input_trials]))\n",
    "   \n",
    "\n",
    "\n",
    "    lc_rewards_flipped = np.vstack((lc_rewards_flipped[:n_input_trials,:], lc_rewards_flipped[mv_slice:mv_slice+n_input_trials,:]))\n",
    "    lc_cumulative_p = np.hstack((lc_cumulative_p[:n_input_trials], lc_cumulative_p[mv_slice:mv_slice+n_input_trials]))\n",
    "    lc_cprob_epoch = np.hstack((lc_cprob_epoch[:n_input_trials], lc_cprob_epoch[mv_slice:mv_slice+n_input_trials]))\n",
    "    lc_obs_cp_vec = np.hstack((lc_obs_cp_vec[:n_input_trials], lc_obs_cp_vec[mv_slice:mv_slice+n_input_trials]))\n",
    "\n",
    "\n",
    "\n",
    "    mc_rewards_flipped_lv = np.vstack((mc_rewards_flipped_lv[:n_input_trials,:], mc_rewards_flipped_lv[lv_slice:lv_slice+n_input_trials,:]))\n",
    "    mc_cumulative_p_lv = np.hstack((mc_cumulative_p[:n_input_trials], mc_cumulative_p[lv_slice:lv_slice+n_input_trials]))\n",
    "    lv_cprob_epoch = np.hstack((lv_cprob_epoch[:n_input_trials], lv_cprob_epoch[lv_slice:lv_slice+n_input_trials]))\n",
    "    mc_obs_cp_vec_lv = np.hstack((mc_obs_cp_vec_lv[:n_input_trials], mc_obs_cp_vec_lv[lv_slice:lv_slice+n_input_trials]))\n",
    "\n",
    "\n",
    "    mc_rewards_flipped_hv = np.vstack((mc_rewards_flipped_hv[:n_input_trials,:], mc_rewards_flipped_hv[hv_slice:hv_slice+n_input_trials,:]))\n",
    "    mc_cumulative_p_hv = np.hstack((mc_cumulative_p[:n_input_trials], mc_cumulative_p[hv_slice:hv_slice+n_input_trials]))\n",
    "    hv_cprob_epoch = np.hstack((hv_cprob_epoch[:n_input_trials], hv_cprob_epoch[hv_slice:hv_slice+n_input_trials]))\n",
    "    mc_obs_cp_vec_hv = np.hstack((mc_obs_cp_vec_hv[:n_input_trials], mc_obs_cp_vec_hv[hv_slice:hv_slice+n_input_trials]))\n",
    "\n",
    "\n",
    "        \n",
    "    return (hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p_lv,mc_cumulative_p_hv,lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_trial_structure(hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p_lv,mc_cumulative_p_hv, lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards, filenames = ['test_highC', 'test_lowC', 'test_lowV', 'test_highV']):\n",
    "\n",
    "    #print \n",
    "    filename = filenames[0]\n",
    "    taskParameters = np.array((hc_rewards_flipped[:,0], hc_rewards_flipped[:,1], hc_cumulative_p, hc_cprob_epoch, 1-hc_cprob_epoch, mv_cp_vec, hc_obs_cp_vec, mu_rewards, std_rewards))\n",
    "    taskParameters = np.matrix.transpose(taskParameters)\n",
    "    header = (\"r_t1, r_t2, c_prob, c_prob_epoch_t0, c_prob_epoch_t1, cp, obs_cp, mu_rewards, std_rewards\") \n",
    "    np.savetxt(filename + '.csv',taskParameters, header = header, delimiter=',', comments = '', fmt='%f')\n",
    "\n",
    "    filename = filenames[1]\n",
    "    taskParameters = np.array((lc_rewards_flipped[:,0],  lc_rewards_flipped[:,1], lc_cumulative_p, lc_cprob_epoch, 1-lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mu_rewards, std_rewards))\n",
    "    taskParameters = np.matrix.transpose(taskParameters)\n",
    "    header = (\"r_t1, r_t2, c_prob, c_prob_epoch_t0, c_prob_epoch_t1,cp, obs_cp, mu_rewards, std_rewards\") \n",
    "    np.savetxt(filename + '.csv',taskParameters, header = header, delimiter=',', comments = '', fmt='%f')\n",
    "\n",
    "    filename = filenames[2]\n",
    "    taskParameters = np.array(( mc_rewards_flipped_lv[:,0], mc_rewards_flipped_lv[:,1], mc_cumulative_p_lv,lv_cprob_epoch, 1-lv_cprob_epoch,lv_cp_vec, mc_obs_cp_vec_lv, mu_rewards, std_rewards))\n",
    "    taskParameters = np.matrix.transpose(taskParameters)\n",
    "    header = (\"r_t1, r_t2, c_prob, c_prob_epoch_t0, c_prob_epoch_t1, cp, obs_cp,mu_rewards, std_rewards\") \n",
    "    np.savetxt(filename + '.csv',taskParameters, header = header, delimiter=',', comments = '', fmt='%f')\n",
    "\n",
    "    filename = filenames[3]\n",
    "    taskParameters = np.array(( mc_rewards_flipped_hv[:,0], mc_rewards_flipped_hv[:,1], mc_cumulative_p_hv,hv_cprob_epoch,1-hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards))\n",
    "    taskParameters = np.matrix.transpose(taskParameters)\n",
    "    header = (\"r_t1, r_t2, c_prob, c_prob_epoch_t0, c_prob_epoch_t1, cp, obs_cp, mu_rewards, std_rewards\") \n",
    "    np.savetxt(filename + '.csv',taskParameters, header = header, delimiter=',', comments = '', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = np.arange(0,1)\n",
    "\n",
    "# subjects = np.arange(0,1)\n",
    "min_epoch_length = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s_idx in subjects: \n",
    "    cp = [0,1]\n",
    "    filenames = ['hc', 'lc', 'lv', 'hv']\n",
    "    filenames=[fn+'_'+str(s_idx) for fn in filenames]\n",
    "    failed=True \n",
    "    while failed:    \n",
    "        (lc_binary_t0, lc_binary_t1, mc_binary_t0,mc_binary_t1, hc_binary_t0, hc_binary_t1, hc_cumulative_p, mc_cumulative_p, lc_cumulative_p, n_trials) = define_prob_vectors()\n",
    "\n",
    "        (hc_rewards, mc_rewards, lc_rewards, \n",
    "                   hc_rewards_t0, hc_rewards_t1, mc_rewards_t0, mc_rewards_t1, \n",
    "                   lc_rewards_t0, lc_rewards_t1, mu_rewards, std_rewards) = assign_reward_values(lc_binary_t0, lc_binary_t1, mc_binary_t0, mc_binary_t1, hc_binary_t0, hc_binary_t1,n_trials)\n",
    "\n",
    "        (hv_lam, mv_lam, lv_lam) = assign_changepoint_indices(n_trials)\n",
    "\n",
    "\n",
    "        (lc_rewards_flipped, mc_rewards_flipped,mc_rewards_flipped_lv, mc_rewards_flipped_hv,hc_rewards_flipped, cp_lv_epoch_len, cp_mv_epoch_len, cp_hv_epoch_len, cp_lv_epoch_idx, cp_hv_epoch_idx,cp_mv_epoch_idx, lv_cp_vec, mv_cp_vec, hv_cp_vec) = write_changepoints(lc_rewards_t0, mc_rewards_t0, hc_rewards_t0, \n",
    "        lc_rewards_t1, mc_rewards_t1, hc_rewards_t1,\n",
    "        hv_lam, mv_lam, lv_lam,n_trials)\n",
    "\n",
    "\n",
    "        (lc_obs_cp_vec,mc_obs_cp_vec,mc_obs_cp_vec_lv,\n",
    "        mc_obs_cp_vec_hv,hc_obs_cp_vec) = write_obs_changepoints(lc_rewards_flipped, mc_rewards_flipped,mc_rewards_flipped_lv, mc_rewards_flipped_hv,hc_rewards_flipped,n_trials)\n",
    "\n",
    "        (lc_cprob_epoch, hc_cprob_epoch,hv_cprob_epoch,lv_cprob_epoch) = calc_empirical_cprob(cp_lv_epoch_len,cp_mv_epoch_len, cp_hv_epoch_len, cp_mv_epoch_idx, cp_lv_epoch_idx, cp_hv_epoch_idx,\n",
    "                                lc_rewards_flipped, mc_rewards_flipped_hv,mc_rewards_flipped_lv, hc_rewards_flipped,n_trials)\n",
    "\n",
    "\n",
    "        (hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p_lv,mc_cumulative_p_hv,lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards)  = slice_trials(hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p,lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards, n_input_trials=300)\n",
    "        \n",
    "        failed=False\n",
    "        for cp in [mv_cp_vec,lv_cp_vec,hv_cp_vec]:\n",
    "            test=cp\n",
    "            np.insert(test,0,0)\n",
    "            np.append(test,600)\n",
    "            failed |= np.sum(np.diff(np.argwhere(test),axis=0)< min_epoch_length) > 1\n",
    "#             failed |= np.min(np.diff(np.argwhere(test),axis=0))< min_epoch_length\n",
    "            print(np.sum(np.diff(np.argwhere(test),axis=0)< min_epoch_length))\n",
    "        \n",
    "    print_trial_structure(hc_rewards_flipped, hc_cumulative_p, hc_cprob_epoch, hc_obs_cp_vec, lc_rewards_flipped, lc_cumulative_p, lc_cprob_epoch, mv_cp_vec, lc_obs_cp_vec, mc_rewards_flipped_lv, mc_cumulative_p_lv,mc_cumulative_p_hv, lv_cprob_epoch, lv_cp_vec, mc_obs_cp_vec_lv, mc_rewards_flipped_hv,hv_cprob_epoch, hv_cp_vec, mc_obs_cp_vec_hv, mu_rewards, std_rewards, filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
